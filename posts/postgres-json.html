<!doctype html>
<html lang="en">
<title>Wes Doyle</title>
<head>
    <link href="https://fonts.googleapis.com/css?family=Noto+Serif|Roboto+Mono" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans&display=swap" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="../styles.css">
</head>
<body>
<div class="wrapper">
    <nav class="header">
        <div class="navBar">
            <a href="https://wesdoyle.net" id="wes-console">wes_doyle >
                <div class="cursor-wrapper">
                    <span class="blinking-cursor">_</span>
                </div>
            </a>
            <ul>
                <li><a href="https://wesdoyle.net">Home</a></li> /
                <li><a href="reading.html">Reading List</a></li> /
                <li><a href="projects.html">Current Projects</a></li>
            </ul>
        </div>
    </nav>

    <hr>

    <section class="content-article">
        <main class="main">
            <h2>Malformed Data Parsing adventures In Postgres</h2>
            <div class="article">
                <p>Sometimes the trickiest part of an ETL problem is transforming the raw data you have into a useful format.  In this post, I'll walk through an interesting data serialization problem, and explore a few Postgres functions that I leveraged.</p>
                <p>I was recently working on a project involving some data containing malformed JSON (we'll look at the format in a moment) stored in several Postgres database tables as text.  I'm not sure how the data was serialized into this format when it was originally loaded, but the end goal of this project involved writing a number of database triggers and functions that parsed the tables containing this raw data and inserting transformed, new data into other tables.</p>
                <p>The raw import table consisted of approximately ~1M rows and having about a dozen columns of varying Character and Numeric types, including a column we'll call "commerce" with malformed JSON-like objects stored as text.</p>
                <p>Upon brief inspection, it looked like the data in the "commerce" column was very close to being valid JSON, and all of the records I inspected appeared to have the same malformations - unquoted numeric properties, internal single-quoting of properties and values, and a pair of double quotes surrounding the entire object. Apart from that, one minor caveat was that it looked like data in a property called "Meta" was a comma-separated list stored as a string rather than an array.</p>
                <p>So, an example value in the "commerce" column looked something like this:</p>

                <div class="code-block">
                    <span class="identifier">SELECT</span> commerce
                    <span class="identifier">FROM</span> import_data
                    <span class="identifier">LIMIT</span> <span class="constant">1</span>;
                    <div class="output">
                        <div class="output-header">result</div>
                        <p class="output-content">"{0:{'Origine': 'Lyon','DestID': 123, 'Meta': 'Foo, Bar, Baz'},1: {'Origine': 'Strasbourg','DestID': 3432, 'Meta': 'Foo, Quux'}}"</p>
                    </div>
                </div>

                <p>As you can see, this is almost JSON. We have three minor issues to resolve before it is valid. </p>
                <p>We need to:</p>

                <ul>
                    <li>Eliminate the outermost double-quotes</li>
                    <li>Replace internal single-quotes with double quotes</li>
                    <li>Wrap the single digit properties at the first level of the parent object in double quotes.</li>
                </ul>

                <p>One of the many reasons I love Postgres is that it provides a robust set of <a href="https://www.postgresql.org/docs/current/functions-json.html" target="_blank">Functions and Operators</a> to work with JSON. In making these transformations, we'd have a properly serialized JSON object, allowing us to take advantage of these features. Proper serialization here would make downstream operations on this data much easier to implement.  Unfortunately, since I didn't control how the data gets imported, I'd need to implement a post-hoc solution on the existing import.</p>
                <p>Postgres provides support for pattern matching using POSIX-style regular expressions. Though we could likely construct a single regex to clean the string, I opted to use a combination of functions to clean the string: `left`, `right`, `replace`, and `regexp_replace`.</p>
                <p>We can replace all of the single quotes in the string with double quotes using the Postgres `replace` function.  It looks a bit weird, but escaping single quotes in a string requires four single quotes - two outer quotes for the string, and two inner quotes to represent an escaped single quote. It would also be possible to use a Dollar-Quoted String here.</p>

                <div class="code-block">
                    <span class="identifier">SELECT <span class="operator">replace</span>(</span>"commerce", '''', '"'<span class="identifier">) FROM </span>import_data <span class="identifier">LIMIT</span> <span class="constant">1</span>;
                    <div class="output">
                        <div class="output-header">result</div>
                        <div class="output-content">
                            <p>{0:{"Origine": "Lyon","DestID": 123, "Meta": "Foo, Bar, Baz"},1: {"Origine": "Strasbourg","DestID": 3432, "Meta": "Foo, Quux"}}"</p>
                        </div>
                    </div>
                </div>

                <p>We can remove the leading and trailing double quotes using `left` and `right` functions:</p>

                <div class="code-block">
                    <span class="identifier">SELECT</span><br/>
                    <span class="operator">&nbsp;&nbsp;left</span><span class="identifier">(</span><br/>
                    <span class="operator">&nbsp;&nbsp;&nbsp;&nbsp;right</span><span class="identifier">(</span><br/>
                    <span class="operator">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replace</span><span class="identifier">(</span>commerce, '''', '"'<span class="identifier">)</span>,<br/>
                    <span class="constant">&nbsp;&nbsp;&nbsp;&nbsp; -1</span><span class="identifier">)</span>,<br/>
                    &nbsp;&nbsp;<span class="constant">-1</span><span class="identifier">)</span><br/>
                    <span class="identifier">FROM</span> import_data <span class="identifier">LIMIT</span> <span class="constant">1</span>;<br/>

                    <div class="output">
                        <div class="output-header">result</div>
                        <div class="output-content">
                            <p>{0:{"Origine": "Lyon","DestID": 123, "Meta": "Foo, Bar, Baz"},1: {"Origine": "Strasbourg","DestID": 3432, "Meta": "Foo, Quux"}}</p>
                        </div>
                    </div>
                </div>

                <p>We can use `regexp_replace` to replace the non-double-quoted digit properties with double quotes, and finally cast the output as Postgres's JSONB data type.</p>

                <div class="code-block">
                    <span class="identifier">SELECT</span><br/>
                    <span class="operator">&nbsp;&nbsp;left</span><span class="identifier">(</span><br/>
                    <span class="operator">&nbsp;&nbsp;&nbsp;&nbsp;right</span><span class="identifier">(</span><br/>
                    <span class="operator">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;regexp_replace</span><span class="identifier">(</span><br/>
                    <span class="operator">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replace</span><span class="identifier">(</span>commerce, '''', '"'<span class="identifier">)</span>,<br/>
                    <span class="type">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="identifier">'([0-9]+):'</span>, <span class="type">'"\1":'</span>, <span class="type">'g'</span><span class="identifier">)</span>,<br/>
                    <span class="constant">&nbsp;&nbsp;&nbsp;&nbsp; -1</span><span class="identifier">)</span>,<br/>
                    &nbsp;&nbsp;<span class="constant">-1</span><span class="identifier">)</span><span class="constant">::jsonb</span>;<br/>
                    <span class="identifier">AS</span> commerce_cleaned<br/>
                    <span class="identifier">FROM</span> import_data <span class="identifier">LIMIT</span> <span class="constant">1</span>;<br/>

                    <div class="output">
                        <div class="output-header">result</div>
                        <div class="output-content">
                            <p>{"0": {"Meta": "Foo, Bar, Baz", "DestID": 123, "Origine": "Lyon"}, "1": {"Meta": "Foo, Quux", "DestID": 3432, "Origine": "Strasbourg"}}</p>
                        </div>
                    </div>
                </div>

                <p>This will take the value in the commerce column, create a capture group around digits preceding a colon, and replace them with the capture group surrounded by double quotes and a trailing colon, searching globally in the field.  It's required to explicitly look for numbers followed by a colon because the string contains other numerals that are property values.</p>
                <p>Wrapping this expression in a function that takes an initial text value will make things more readable when we use it in composing downstream procedures:</p>

                <div class="code-block">
                    <span class="identifier">CREATE OR REPLACE FUNCTION</span> <span class="operator">clean_commerce</span><span class="identifier">(</span>t text<span class="identifier">)</span>
                    <span class="identifier">RETURNS</span> jsonb AS <span class="constant">$$</span><br/>
                    <span class="identifier">BEGIN</span><br/>
                    &nbsp;&nbsp;<span class="identifier">RETURN</span><br/>
                    &nbsp;&nbsp;<span class="operator">&nbsp;&nbsp;left</span><span class="identifier">(</span><br/>
                    &nbsp;&nbsp;<span class="operator">&nbsp;&nbsp;&nbsp;&nbsp;right</span><span class="identifier">(</span><br/>
                    &nbsp;&nbsp;<span class="operator">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;regexp_replace</span><span class="identifier">(</span><br/>
                    &nbsp;&nbsp;<span class="operator">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replace</span><span class="identifier">(</span>t, '''', '"'<span class="identifier">)</span>,<br/>
                    &nbsp;&nbsp;<span class="type">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="identifier">'([0-9]+):'</span>, <span class="type">'"\1":'</span>, <span class="type">'g'</span><span class="identifier">)</span>,<br/>
                    &nbsp;&nbsp;<span class="constant">&nbsp;&nbsp;&nbsp;&nbsp; -1</span><span class="identifier">)</span>,<br/>
                    &nbsp;&nbsp;&nbsp;&nbsp;<span class="constant">-1</span><span class="identifier">)</span><span class="constant">::jsonb</span>;<br/>
                    <span class="identifier">END</span>;<br/>
                    <span class="constant">$$</span> <span class="identifier">LANGUAGE</span> plpgsql;<br/>
                </div>

                <p>Now, we can simply run a query like:</p>

                <div class="code-block">

                    <span class="identifier">SELECT</span> <span class="operator">clean_commerce</span><span class="identifier">(</span>commerce<span class="identifier">)</span> <span class="identifier">FROM</span> import_data;

                    <div class="output">
                        <div class="output-header">result</div>
                        <div class="output-content">
                            <p>{"0": {"Meta": "Foo, Bar, Baz", "DestID": 123, "Origine": "Lyon"}, "1": {"Meta": "Foo, Quux", "DestID": 3432, "Origine": "Strasbourg"}}</p>
                        </div>
                    </div>
                </div>

                <p>With some basic sanitation in place, we can now take advantage of Postgres's builtin JSON support. For example, in a downstream trigger, we can use the `->` operator to select and parse out separate columns for the "0" and "1" sub-objects.</p>
                <p>Let's say we wanted to populate a table <span class="emphasis">parsed_data</span> to capture values from the "Origine" Meta object keys whenever new new records are inserted into the <span class="emphasis">import_data</span> table. For example:</p>

                <div class="code-block">
                    <span class="comment">-- Create Trigger Function</span><br />
                    <br />
                    <span class="identifier">CREATE OR REPLACE FUNCTION</span> <span class="operator">parse_import_data</span><span class="identifier">()</span><br />
                    &nbsp;&nbsp;<span class="identifier">RETURNS</span> trigger <span class="identify">AS</span><br />
                    &nbsp;&nbsp;<span class="identifier">$BODY$</span><br />
                    &nbsp;&nbsp;<span class="identifier">BEGIN</span><br />
                    &nbsp;&nbsp;&nbsp;&nbsp;<span class="identifier">INSERT INTO</span> <span class="operator">parsed_data</span> <span class="identifier">(</span>id<span class="identifier">,</span> origine_1<span class="identifier">,</span> origine_2<span class="identifier">)</span><br />
                    &nbsp;&nbsp;&nbsp;&nbsp;<span class="identifier">VALUES</span> <span class="operator">(</span><br />
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NEW.id,<br />
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="operator">clean_commerce</span><span class="identifier">(</span>NEW.commerce<span class="operator">)</span><span class="operator">-></span>'0'<span class="operator">->></span>'Origine',<br />
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="operator">clean_commerce</span><span class="identifier">(</span>NEW.commerce<span class="operator">)</span><span class="operator">-></span>'1'<span class="operator">->></span>'Origine'<br />
                    &nbsp;&nbsp;&nbsp;&nbsp;<span class="operator">)</span>;<br />
                    &nbsp;&nbsp;&nbsp;&nbsp;<span class="identifier">RETURN NEW</span>;<br />
                    &nbsp;&nbsp;<span class="identifier">END</span>;<br />
                    <span class="identifier">$BODY$ LANGUAGE</span> plpgsql;<br />
                </div>

                <div class="code-block">
                    <span class="comment">-- Create Insert Trigger</span><br />
                    <br />
                    <span class="identifier">CREATE TRIGGER</span> parse_insert_data<br />
                    &nbsp;&nbsp;<span class="identifier">BEFORE INSERT</span><br />
                    &nbsp;&nbsp;<span class="identifier">ON</span> import_data<br />
                    &nbsp;&nbsp;<span class="identifier">FOR EACH ROW</span><br />
                    &nbsp;&nbsp;<span class="identifier">EXECUTE PROCEDURE</span>  <span class="operator">parse_import_data</span><span class="identifier">()</span>;<br />
                </div>

                <p>So, for values in the original malformed-data version of the column 'commerce' like:</p>

                <table>
                    <tr>
                        <th>
                            id
                        </th>
                        <th>
                            commerce
                        </th>
                    </tr>
                    <tr>
                        <td>
                            1
                        </td>
                        <td>
                            "{0:{'Origine': 'Lyon','DestID': 230, 'Meta': 'Foo, Dan K, dank@foo.bar'},1: {'Origine': 'Strasbourg','DestID': 851, 'Meta': 'Foo, N Yama, yaman@example.com'}}"
                        </td>
                    </tr>
                    <tr>
                        <td>
                            2
                        </td>
                        <td>
                            "{0:{'Origine': 'Bonn','DestID': 310, 'Meta': 'Bar, E Smith, esm@foo.bar'},1: {'Origine': 'Strasbourg','DestID': 912, 'Meta': 'Foo, Arkadij J, arky@cent.org'}}"
                        </td>
                    </tr>
                </table>

                <p>The resulting records in parsed_data for an import_data.commerce value would become:</p>

                <table>
                    <tr>
                        <th>id</th>
                        <th>origine_1</th>
                        <th>origine_2</th>
                    </tr>
                    <tr>
                        <td>1</td>
                        <td>Lyon</td>
                        <td>Strasbourg</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td>Bonn</td>
                        <td>Strasbourg</td>
                    </tr>
                </table>

                <p>Another interesting problem in this dataset involved the "Meta" property in the extracted JSON object.  As you can see, it's a string with comma-separated values of varying length.  As it turned out, there was some meaning to the number of items in the list.  If the first value of the comma-separated string at the "Meta" property was either "Foo" or "Bar," the string had three comma-separated values, which mapped to properties called "Accord", "Nom", and "Email", respectively.</p>
                <p>For first values of "Baz", "Quux", or "Jam," the Meta property had two values mapped to an "Accord" and an "Email," respectively.  As part of the pipeline, I needed to extract this data to a table, as well.  Again, PostgreSQL JSON support helped make the task relatively easy.</p>
                <p>First, we define a function to convert the comma separated text values to a proper JSONB array.  For this, we can use a combination of the function concat to prepend and append curly braces around the selector, cast the result to a text array type, and pass the result to the builtin function array_to_json. Note that this function is specific to the structure of the data we're importing, which was determined by inspection.</p>

                <div class="code-block">
                    <div class="comment">
                        /**<br />
                        Function to create JSONB array from Meta CSV text value<br />
                        */
                        <br />
                        <br />
                    </div>
                    <span class="identifier">CREATE OR REPLACE FUNCTION</span> <span class="operator">commerce_meta_to_array</span><span class="identifier">(</span>obj jsonb, prop text<span class="identifier">)</span><br />
                    &nbsp;&nbsp;<span class="identifier">RETURNS</span> jsonb <span class="identifier">AS</span> <span class="constant">$$</span><br />
                    &nbsp;&nbsp;<span class="identifier">BEGIN</span><br />
                    &nbsp;&nbsp;&nbsp;&nbsp;<span class="identifier">RETURN</span><br />
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="operator">array_to_json</span><span class="identifier">(</span><span class="operator">concat</span><span class="identifier">(</span>'{', obj <span class="operator">-></span> prop <span class="operator">->></span>'Meta', '}'<span class="identifier">)</span><span class="constant">::text[]</span><span class="identifier">)</span><span class="constant">::jsonb</span>;<br />
                    &nbsp;&nbsp;<span class="identifier">END</span>;<br />
                    &nbsp;&nbsp;<span class="constant">$$</span> <span class="identifier">LANGUAGE</span> plpgsql;<br />
                </div>

                <p>Now we can use this to parse the raw data, using the ->> operator to select the appropriate index of the value in the array depending on its first value.  I'm wrapping the initial query in a CTE to be able to query the array_to_json objects as columns.</p>

                <div class="code-block">
                    <span class="identifier">WITH</span> cte <span class="identifier">AS (SELECT</span><br />
                    &nbsp;&nbsp;id,<br />
                    &nbsp;&nbsp;<span class="operator">commerce_meta_to_array</span><span class="identifier">(</span><span class="operator">clean_commerce</span><span class="identifier">(</span>commerce<span class="identifier">)</span>, '0'<span class="identifier">)</span> buyer,<br />
                    &nbsp;&nbsp;<span class="operator">commerce_meta_to_array</span><span class="identifier">(</span><span class="operator">clean_commerce</span><span class="identifier">(</span>commerce<span class="identifier">)</span>, '1'<span class="identifier">)</span> seller<br />
                    &nbsp;&nbsp;<span class="identifier">FROM</span> import_data<span class="identifier">)</span><br />
                    <br />
                    <span class="identifier">SELECT</span><br />
                    &nbsp;&nbsp;id,<br />
                    &nbsp;&nbsp;buyer <span class="operator">->></span> 0 accord_0,<br />
                    &nbsp;&nbsp;seller <span class="operator">->></span> 0 accord_1,<br />
                    &nbsp;&nbsp;<span class="identifier">CASE WHEN</span> buyer <span class="operator">->></span> 0 <span class="identifier">IN (</span>'Foo', 'Bar'<span class="identifier">) THEN </span>buyer <span class="operator">->></span> 1 <span class="identifier">ELSE NULL END </span>nom_0,<br />
                    &nbsp;&nbsp;<span class="identifier">CASE WHEN</span> buyer <span class="operator">->></span> 0 <span class="identifier">IN (</span>'Foo', 'Bar'<span class="identifier">) THEN </span>buyer <span class="operator">->></span> 2 <span class="identifier">ELSE</span> buyer <span class="operator">->></span> 1 <span class="identifier">END</span> email_0,<br />
                    &nbsp;&nbsp;<span class="identifier">CASE WHEN</span> seller <span class="operator">->></span> 0 <span class="identifier">IN (</span>'Foo', 'Bar'<span class="identifier">) THEN </span>seller <span class="operator">->></span> 1 <span class="identifier">ELSE NULL END</span> nom_1,<br />
                    &nbsp;&nbsp;<span class="identifier">CASE WHEN</span> seller <span class="operator">->></span> 0 <span class="identifier">IN (</span>'Foo', 'Bar'<span class="identifier">) THEN </span>seller <span class="operator">->></span> 2 <span class="identifier">ELSE</span> seller <span class="operator">->></span> 1 <span class="identifier">END</span> email_1<br />
                    <span class="identifier">FROM</span> cte;<br />

                </div>

                <p>Again, for the malformed import_data column containing the following records:</p>

                "{0:{'Origine': 'Lyon','DestID': 230, 'Meta': 'Foo, Dan K, dank@foo.bar'},1: {'Origine': 'Strasbourg','DestID': 851, 'Meta': 'Foo, N Yama, yaman@example.com'}}"<br />
                "{0:{'Origine': 'Bonn','DestID': 310, 'Meta': 'Bar, E Smith, esm@foo.bar'},1: {'Origine': 'Strasbourg','DestID': 912, 'Meta': 'Foo, Arkadij J, arky@cent.org'}}"<br />
                "{0:{'Origine': 'Bremen','DestID': 12, 'Meta': 'Baz, zsh@foo.bar'},1: {'Origine': 'Strasbourg','DestID': 32, 'Meta': 'Jam, bin_341@foo.baz'}}"<br />
                "{0:{'Origine': 'Bettembourg','DestID': 64, 'Meta': 'Jam, obs23@baz.org'},1: {'Origine': 'Strasbourg','DestID': 29, 'Meta': 'Quux, sent@h.baz'}}"<br />

                <p>The CTE query produces the following table:</p>

                <table>
                    <tr>
                        <th>id</th>
                        <th>accord_0</th>
                        <th>accord_1</th>
                        <th>nom_0</th>
                        <th>email_0</th>
                        <th>nom_1</th>
                        <th>email_1</th>
                    </tr>
                    <tr>
                        <td>1</td>
                        <td>Foo</td>
                        <td>Foo</td>
                        <td>Dan K</td>
                        <td>dank@foo.bar</td>
                        <td>N Yama</td>
                        <td>yaman@example.com</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td>Bar</td>
                        <td>Foo</td>
                        <td>E Smith</td>
                        <td>esm@foo.bar</td>
                        <td>Arkadij J</td>
                        <td>arky@cent.org</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>Baz</td>
                        <td>Jam</td>
                        <td>null</td>
                        <td>zsh@foo.bar</td>
                        <td>null </td>
                        <td>bin_341@foo.baz</td>
                    </tr>
                    <tr>
                        <td>4</td>
                        <td>Bar</td>
                        <td>Foo</td>
                        <td>null</td>
                        <td>obs23@baz.org</td>
                        <td>null</td>
                        <td>send@h.baz</td>
                    </tr>
                </table>
                <p>I'd like to investigate optimizations here, as I suspect that the nested function calls and type casting are expensive.  In short, it has been fun to explore Postgres support for text and JSON data.</p>
            </div>
            <hr />
        </main>
    </section>
</div>
</body>
</html>

